import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

# ==========================================
# 1. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (ë°˜ë“œì‹œ ìˆì–´ì•¼ ë¡œë“œ ê°€ëŠ¥)
# ==========================================

# ë§¨ ì²˜ìŒ yê°’ì„ ì¤„ ë•Œ ì˜ˆì¸¡ xë¥¼ ë‚´ë±‰ëŠ” MLP(í•™ìŠµì‹œì¼œì•¼ í•¨)
class InverseNet_PaperSpec(nn.Module):
    def __init__(self, input_dim=201, output_dim=8):
        super(InverseNet_PaperSpec, self).__init__()
        # ë…¼ë¬¸ ìŠ¤í™: ì€ë‹‰ì¸µ 4ê°œ, ë‰´ëŸ° 1000ê°œ
        # Batch Normê³¼ Dropoutì€ ìµœì‹  íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•´ ì¶”ê°€
        self.model = nn.Sequential(
            # Layer 1
            nn.Linear(input_dim, 1000),
            nn.BatchNorm1d(1000),
            nn.ReLU(),
            nn.Dropout(0.1),
            # Layer 2
            nn.Linear(1000, 1000),
            nn.BatchNorm1d(1000),
            nn.ReLU(),
            nn.Dropout(0.1),
            # Layer 3
            nn.Linear(1000, 1000),
            nn.BatchNorm1d(1000),
            nn.ReLU(),
            nn.Dropout(0.1),
            # Layer 4
            nn.Linear(1000, 1000),
            nn.BatchNorm1d(1000),
            nn.ReLU(),

            # Output Layer (ë‘ê»˜ 8ê°œ ì¶œë ¥)
            nn.Linear(1000, output_dim)
        )

    def forward(self, x):
        return self.model(x)


# 2. íƒ ë¤ ë„¤íŠ¸ì›Œí¬ ì •ì˜ (Inverse + Frozen Forward)
class TandemNet(nn.Module):
    def __init__(self, inverse_model, forward_model):
        super(TandemNet, self).__init__()
        self.inverse_model = inverse_model
        self.forward_model = forward_model

        # Forward Modelì€ í•™ìŠµí•˜ì§€ ì•Šë„ë¡ ì–¼ë¦¬ê¸°
        self.forward_model.eval()
        for param in self.forward_model.parameters():
            param.requires_grad = False

    def forward(self, spectrum):
        predicted_thickness_norm = self.inverse_model(spectrum) # y -> x_p(ì •ê·œí™” o)
        reconstructed_spectrum = self.forward_model(predicted_thickness_norm) # x_p(ì •ê·œí™” o)-> y_p

        return predicted_thickness_norm, reconstructed_spectrum # x_p, y_p ì¶œë ¥

    def train(self, mode=True):
      super(TandemNet, self).train(mode) # ì¼ë‹¨ ì „ì²´ë¥¼ ëª¨ë“œì— ë§ê²Œ ë³€ê²½
      self.forward_model.eval()          # ê·¸ ë‹¤ìŒ Forwardë§Œ ê°•ì œë¡œ evalë¡œ ê³ ì •
      return self
    

# Forward Model (ì‹œë®¬ë ˆì´í„° ëŒ€ì²´ìš©)
# ì™„ì „ì—´ê²° MLP ëª¨ë¸ êµ¬í˜„
class MLP(nn.Module):
    def __init__(self, input_dim = 8, output_dim =201, hidden_dim_1=250, hidden_dim_2=250, hidden_dim_3=250, hidden_dim_4=250):
        super(MLP, self).__init__() # ë¶€ëª¨ í´ë˜ìŠ¤ __init__ ì‹¤í–‰
        self.model = nn.Sequential(
            # 1ë²ˆì§¸ ì¸µ 8 -> 250
            nn.Linear(input_dim, hidden_dim_1),
            nn.ReLU(),
            # 2ë²ˆì§¸ ì¸µ 250 -> 250
            nn.Linear(hidden_dim_1, hidden_dim_2),
            nn.ReLU(),
            # 3ë²ˆì§¸ ì¸µ 250 -> 250
            nn.Linear(hidden_dim_2, hidden_dim_3),
            nn.ReLU(),
            # 4ë²ˆì§¸ ì¸µ 250 -> 250
            nn.Linear(hidden_dim_3, hidden_dim_4),
            nn.ReLU(),
            # 5ë²ˆì§¸ ì¸µ 250 -> 201
            nn.Linear(hidden_dim_4, output_dim)
        )

        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (ë…¼ë¬¸: Normal dist, mean=0, std=0.1)
        self._initialize_weights() # ì •ê·œë¶„í¬ë¡œ ê°€ì¤‘ì¹˜, bios ì´ˆê¸°í™”

    def forward(self, x):
        return self.model(x)

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, mean=0, std=0.1)
                nn.init.normal_(m.bias, mean=0, std=0.1)


# ==========================================
# 2. ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ (ìºì‹±ìœ¼ë¡œ ì†ë„ í–¥ìƒ)
# ==========================================
@st.cache_resource
def load_models():
    device = torch.device('cpu') # ì„œë²„ì—ëŠ” GPUê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë‹ˆ CPUë¡œ
    
    # ê¹¡í†µ ëª¨ë¸ ìƒì„±
    f_model = MLP().to(device)
    i_model = InverseNet_PaperSpec().to(device)
    t_model = TandemNet(i_model, f_model).to(device)
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ (íŒŒì¼ ì´ë¦„ì´ ì •í™•í•´ì•¼ í•¨!)
    # ë§Œì•½ Tandem ì•ˆì— Forwardê°€ í¬í•¨ë˜ì–´ ì €ì¥ëë‹¤ë©´ tandemë§Œ ë¡œë“œí•´ë„ ë¨
    try:
        t_model.load_state_dict(torch.load('tandem_model_change1.pth', map_location=device))
    except:
        st.error("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GitHubì— .pth íŒŒì¼ì„ ì˜¬ë ¸ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    
    t_model.eval()
    return t_model, device

# ==========================================
# 3. ë°ì´í„° ì •ê·œí™” ê°’ (í•˜ë“œì½”ë”© ì¶”ì²œ)
# ==========================================
# Colabì—ì„œ print(train_dataset.mean), print(train_dataset.std) í•´ì„œ ë‚˜ì˜¨ ê°’ì„ ì ìœ¼ì„¸ìš”.
MEAN_THICKNESS = np.array([50.0195, 50.12645, 50.055504, 50.020386, 50.059242, 50.0466, 50.054993, 50.047863])  
STD_THICKNESS = np.array([12.729691, 12.730785, 12.685574, 12.686402, 12.647134, 12.705547, 12.759413, 12.76598])  

# ==========================================
# 4. ë©”ì¸ í™”ë©´ (UI)
# ==========================================
st.title("ğŸŒˆ AI Nano-Photonic Inverse Design")
st.markdown("ì›í•˜ëŠ” **ìŠ¤í™íŠ¸ëŸ¼(ë°˜ì‚¬ìœ¨ íŒ¨í„´)**ì„ ì…ë ¥í•˜ë©´, AIê°€ ê·¸ êµ¬ì¡°ë¥¼ ë§Œë“œëŠ” **ë‚˜ë…¸ ë°•ë§‰ ë‘ê»˜**ë¥¼ ì°¾ì•„ì¤ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì…ë ¥
st.sidebar.header("Target Spectrum ì„¤ì •")
target_wl = st.sidebar.slider("ì¤‘ì‹¬ íŒŒì¥ (Center Wavelength)", 400, 800, 600)
width = st.sidebar.slider("ë°˜ì‚¬í­ (Width)", 10, 100, 30)

# ì‹¤í–‰ ë²„íŠ¼
if st.button("AI ì„¤ê³„ ì‹œì‘ (Design)"):
    model, device = load_models()
    
    # 1. ê°€ìƒì˜ ëª©í‘œ ìŠ¤í™íŠ¸ëŸ¼ ìƒì„± (Gaussian í˜•íƒœ)
    wavelengths = np.linspace(400, 800, 201)
    target_spectrum = np.exp(-((wavelengths - target_wl)**2) / (2 * width**2))
    
    # 2. AI ì˜ˆì¸¡ (Tandem Network)
    # Numpy -> Tensor ë³€í™˜
    input_tensor = torch.FloatTensor(target_spectrum).unsqueeze(0).to(device)
    
    with torch.no_grad():
        # Tandem ëª¨ë¸ì´ ë‘ê»˜ì™€ ì˜ˆìƒ ìŠ¤í™íŠ¸ëŸ¼ì„ ë™ì‹œì— ë±‰ì–´ì¤Œ
        pred_thickness_norm, recon_spectrum = model(input_tensor)
        
    # 3. ê²°ê³¼ ë³€í™˜ (ì •ê·œí™” í•´ì œ)
    pred_thickness_norm = pred_thickness_norm.cpu().numpy().flatten()
    final_thickness = (pred_thickness_norm * STD_THICKNESS) + MEAN_THICKNESS
    
    # ë²”ìœ„ ê°•ì œ (30~70nm) - ë³´ê¸° ì¢‹ê²Œ
    final_thickness = np.clip(final_thickness, 30, 70)
    
    # 4. ê²°ê³¼ ì¶œë ¥
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("âœ… ì„¤ê³„ ì™„ë£Œ!")
        st.write("AIê°€ ì œì•ˆí•œ 8ì¸µ ë‘ê»˜ (nm):")
        st.dataframe(final_thickness)
        
    with col2:
        # 5. ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        st.write("ğŸ“Š ìŠ¤í™íŠ¸ëŸ¼ ë¹„êµ ê²€ì¦")
        fig, ax = plt.subplots()
        ax.plot(wavelengths, target_spectrum, 'k--', label='Target (Goal)', linewidth=2)
        ax.plot(wavelengths, recon_spectrum.cpu().numpy().flatten(), 'r-', label='AI Result', linewidth=2)
        ax.set_xlabel("Wavelength (nm)")
        ax.set_ylabel("Normalized Response")
        ax.legend()
        ax.grid(True, alpha=0.3)
        st.pyplot(fig)